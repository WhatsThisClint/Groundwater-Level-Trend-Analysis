{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabab30e-145c-4835-915c-86fd44a00464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1b06b2-6576-4a7a-b1f8-0431689fea1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimiter conversion process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path where your CSV files are located\n",
    "folder_path = 'D:\\IGRAC\\Python\\Waterlevel'\n",
    "\n",
    "# Create a backup folder to store original files\n",
    "backup_folder = os.path.join(folder_path, 'backup')\n",
    "os.makedirs(backup_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the first line of the file to check the delimiter\n",
    "        with open(file_path, 'r') as f:\n",
    "            first_line = f.readline().strip()\n",
    "            if ';' in first_line:  # Change delimiter if it's not a comma\n",
    "                new_file_path = os.path.join(backup_folder, filename)\n",
    "                os.rename(file_path, new_file_path)  # Backup original file\n",
    "                \n",
    "                with open(new_file_path, 'w') as new_f:\n",
    "                    for line in f:\n",
    "                        new_line = line.replace(';', ',')\n",
    "                        new_f.write(new_line)\n",
    "                \n",
    "                print(f\"Converted delimiter for '{filename}' and saved backup\")\n",
    "\n",
    "print(\"Delimiter conversion process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6824aa46-c31d-482c-934b-b806889f03a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from 'WATERLEVEL Andrews.csv'\n",
      "Read data from 'WATERLEVEL Armstrong.csv'\n",
      "Read data from 'WATERLEVEL Baca.csv'\n",
      "Read data from 'WATERLEVEL Bailey.csv'\n",
      "Read data from 'WATERLEVEL Biscoe.csv'\n",
      "Read data from 'WATERLEVEL Borden.csv'\n",
      "Read data from 'WATERLEVEL Carson.csv'\n",
      "Read data from 'WATERLEVEL Castro.csv'\n",
      "Read data from 'WATERLEVEL Cheyenne.csv'\n",
      "Read data from 'WATERLEVEL Cochran.csv'\n",
      "Read data from 'WATERLEVEL Cosby.csv'\n",
      "Read data from 'WATERLEVEL Dallam.csv'\n",
      "Read data from 'WATERLEVEL Dawson.csv'\n",
      "Read data from 'WATERLEVEL Deaf Smith.csv'\n",
      "Read data from 'WATERLEVEL Dickens.csv'\n",
      "Read data from 'WATERLEVEL Donley.csv'\n",
      "Read data from 'WATERLEVEL Floyd.csv'\n",
      "Read data from 'WATERLEVEL Gaines.csv'\n",
      "Read data from 'WATERLEVEL Garza.csv'\n",
      "Read data from 'WATERLEVEL Glasscock.csv'\n",
      "Read data from 'WATERLEVEL Gray.csv'\n",
      "Read data from 'WATERLEVEL Hale.csv'\n",
      "Read data from 'WATERLEVEL Hansford.csv'\n",
      "Read data from 'WATERLEVEL Hartley.csv'\n",
      "Read data from 'WATERLEVEL Hemphill.csv'\n",
      "Read data from 'WATERLEVEL Hockley.csv'\n",
      "Read data from 'WATERLEVEL Howard.csv'\n",
      "Read data from 'WATERLEVEL Hutchinson.csv'\n",
      "Read data from 'WATERLEVEL Kansas 1.csv'\n",
      "Read data from 'WATERLEVEL Kansas 2.csv'\n",
      "Read data from 'WATERLEVEL Kansas 3.csv'\n",
      "Read data from 'WATERLEVEL Kansas 4.csv'\n",
      "Read data from 'WATERLEVEL Kiowa.csv'\n",
      "Read data from 'WATERLEVEL Kit Carson 1.csv'\n",
      "Read data from 'WATERLEVEL Kit Carson 2.csv'\n",
      "Read data from 'WATERLEVEL Lamb.csv'\n",
      "Read data from 'WATERLEVEL Las Animas.csv'\n",
      "Read data from 'WATERLEVEL Lincoln.csv'\n",
      "Read data from 'WATERLEVEL Lipscomb.csv'\n",
      "Read data from 'WATERLEVEL Logan.csv'\n",
      "Read data from 'WATERLEVEL Lubbock.csv'\n",
      "Read data from 'WATERLEVEL Lynn.csv'\n",
      "Read data from 'WATERLEVEL Martin.csv'\n",
      "Read data from 'WATERLEVEL Midland.csv'\n",
      "Read data from 'WATERLEVEL Moore.csv'\n",
      "Read data from 'WATERLEVEL Motley.csv'\n",
      "Read data from 'WATERLEVEL Nabraska.csv'\n",
      "Read data from 'WATERLEVEL New Mexico.csv'\n",
      "Read data from 'WATERLEVEL Ochiltree.csv'\n",
      "Read data from 'WATERLEVEL Oklahoma.csv'\n",
      "Read data from 'WATERLEVEL Oldham.csv'\n",
      "Read data from 'WATERLEVEL Parmer.csv'\n",
      "Read data from 'WATERLEVEL Phillips.csv'\n",
      "Read data from 'WATERLEVEL Potter.csv'\n",
      "Read data from 'WATERLEVEL Prowers.csv'\n",
      "Read data from 'WATERLEVEL Randall.csv'\n",
      "Read data from 'WATERLEVEL Roberts.csv'\n",
      "Read data from 'WATERLEVEL Sedgwick.csv'\n",
      "Read data from 'WATERLEVEL Sherman.csv'\n",
      "Read data from 'WATERLEVEL South Dakota.csv'\n",
      "Read data from 'WATERLEVEL Swisher.csv'\n",
      "Read data from 'WATERLEVEL Terry.csv'\n",
      "Read data from 'WATERLEVEL Washington.csv'\n",
      "Read data from 'WATERLEVEL Wheeler.csv'\n",
      "Read data from 'WATERLEVEL Yoakum.csv'\n",
      "Read data from 'WATERLEVEL Yuma 1.csv'\n",
      "Read data from 'WATERLEVEL Yuma 2.csv'\n",
      "Merged data saved to merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path where your CSV files are located\n",
    "folder_path = 'D:\\IGRAC\\Python\\Waterlevel'\n",
    "\n",
    "# Create a backup folder to store original files\n",
    "backup_folder = os.path.join(folder_path, 'backup')\n",
    "os.makedirs(backup_folder, exist_ok=True)\n",
    "\n",
    "# List to keep track of errors\n",
    "errors = []\n",
    "\n",
    "# List to store DataFrames read from CSV files\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file with the new delimiter\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "            \n",
    "            print(f\"Read data from '{filename}'\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            errors.append(f\"Error processing file '{filename}': {str(e)}\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "merged_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged data to the merged.csv file\n",
    "merged_file_path = os.path.join(folder_path, 'merged.csv')\n",
    "merged_data.to_csv(merged_file_path, index=False)\n",
    "\n",
    "if not errors:\n",
    "    print(\"Merged data saved to merged.csv\")\n",
    "else:\n",
    "    print(\"Merged data saved to merged.csv with the following errors:\")\n",
    "    for error in errors:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fab68f-e9c7-4263-9cd5-eff14faad007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfe004\\AppData\\Local\\Temp\\ipykernel_15644\\1832548528.py:8: DtypeWarning: Columns (1,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(csv_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file:\n",
      "1: AgencyCd\n",
      "2: SiteNo\n",
      "3: Time\n",
      "4: Original Parameter\n",
      "5: Original Direction\n",
      "6: Original Unit\n",
      "7: Original Value\n",
      "8: Accuracy Unit\n",
      "9: Accuracy Value\n",
      "10: Depth to Water Below Land Surface in ft.\n",
      "11: Water level in feet relative to NAVD88\n",
      "12: Comment\n",
      "13: Observation Method\n",
      "14: Data Provided by\n",
      "15: Unnamed: 14\n",
      "16: Water level in feet relative to NGVD29\n",
      "17: Water level in feet relative to MSL\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the numbers of the columns to drop (comma-separated, or 'done' to finish):  4,5,6,7,8,9,12,13,14,15,16,17\n",
      "Enter the numbers of the columns to drop (comma-separated, or 'done' to finish):  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_Waterlevel_Master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ask the user for the name of the CSV file\n",
    "csv_filename = \"Waterlevel_Master.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_filename)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {csv_filename} not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Display the columns to the user\n",
    "print(\"Columns in the CSV file:\")\n",
    "for idx, column in enumerate(data.columns):\n",
    "    print(f\"{idx + 1}: {column}\")\n",
    "\n",
    "# Ask the user for columns to drop\n",
    "columns_to_drop = []\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"Enter the numbers of the columns to drop (comma-separated, or 'done' to finish): \")\n",
    "        if user_input.lower() == 'done':\n",
    "            break\n",
    "        selected_indices = [int(idx) - 1 for idx in user_input.split(\",\")]\n",
    "        valid_indices = [idx for idx in selected_indices if 0 <= idx < len(data.columns)]\n",
    "        columns_to_drop.extend([data.columns[idx] for idx in valid_indices])\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter valid column numbers.\")\n",
    "\n",
    "# Drop the selected columns\n",
    "cleaned_data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_filename = f\"cleaned_{csv_filename}\"\n",
    "cleaned_data.to_csv(cleaned_filename, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583fc31-ed23-4ffa-906c-e8ac25f55fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "4,5,6,7,8,9,12,13,14,15,16,17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
